{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPo5T+yDQy5lP/OWEsWZDUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zelta-7/grade-prediction/blob/main/student_progress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTING FILES\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ZxuQrEFe1Mbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING DATA SET\n",
        "\n",
        "data_maths = pd.read_csv('student-mat.csv', sep=';')\n",
        "data_portuguese = pd.read_csv('student-por.csv', sep=';')\n",
        "\n",
        "print(data_maths.head())\n",
        "missing_m = data_maths.isnull().sum()\n",
        "print(\"Missing value in each column are: \")\n",
        "print(missing_m)\n",
        "\n",
        "print(data_portuguese.head())\n",
        "missing_p = data_portuguese.isnull().sum()\n",
        "print(\"Missing values in each column are: \")\n",
        "print(missing_p)"
      ],
      "metadata": {
        "id": "W5H3J-nZ1qEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXAMINING DATA\n",
        "\n",
        "maths_disc = data_maths.describe()\n",
        "port_disc = data_portuguese.describe()\n",
        "print(\"Description for Maths dataset:\\n\", maths_disc)\n",
        "print(\"Description for Portuguese dataset:\\n\", port_disc)"
      ],
      "metadata": {
        "id": "XgPkATsc312G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENCODING OBJECT TYPE DATA\n",
        "\n",
        "print(\"Data types for maths dataset are: \")\n",
        "print(data_maths.dtypes)\n",
        "print(\"\\nData types for portuguese dataset are: \")\n",
        "print(data_portuguese.dtypes)\n",
        "\n",
        "selected_features = [\"age\", \"sex\", \"studytime\", \"failures\", \"higher\", \"internet\", \"goout\", \"absences\", \"G1\", \"G2\", \"G3\"]\n",
        "\n",
        "data_maths_filtered = data_maths[selected_features]\n",
        "data_encode_m_filtered = pd.get_dummies(data_maths_filtered, drop_first=True)\n",
        "\n",
        "data_portuguese_filtered = data_portuguese[selected_features]\n",
        "data_encode_p_filtered = pd.get_dummies(data_portuguese_filtered, drop_first=True)\n"
      ],
      "metadata": {
        "id": "kNNNaIylGyUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERTING G3 TO BINARY\n",
        "\n",
        "pass_mark = 10\n",
        "data_encode_m_filtered['G3'] = (data_encode_m_filtered['G3'] > pass_mark).astype(int)\n",
        "data_encode_p_filtered['G3'] = (data_encode_p_filtered['G3'] > pass_mark).astype(int)"
      ],
      "metadata": {
        "id": "5Mo3dYM-Ncok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPLITTING THE DATASET 80-20\n",
        "\n",
        "x_m = data_encode_m_filtered.drop('G3', axis=1)\n",
        "y_m = data_encode_m_filtered['G3']\n",
        "x_train_m, x_test_m, y_train_m, y_test_m = train_test_split(x_m, y_m, test_size=0.2, random_state=42)\n",
        "\n",
        "x_p = data_encode_p_filtered.drop('G3', axis=1)\n",
        "y_p = data_encode_p_filtered['G3']\n",
        "x_train_p, x_test_p, y_train_p, y_test_p = train_test_split(x_p, y_p, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jQEmw11kHlQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FEATURE SCALING\n",
        "\n",
        "scaler_m = StandardScaler()\n",
        "x_train_m = scaler_m.fit_transform(x_train_m)\n",
        "x_test_m = scaler_m.transform(x_test_m)\n",
        "\n",
        "scaler_p = StandardScaler()\n",
        "x_train_p = scaler_p.fit_transform(x_train_p)\n",
        "x_test_p = scaler_p.transform(x_test_p)"
      ],
      "metadata": {
        "id": "PvuVaqSlfwTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PERCEPTRON MODEL\n",
        "\n",
        "class Perceptron(object):\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "    self.weight = np.random.normal(loc=0.0, scale=1.0, size=input_dim)\n",
        "    self.bias = np.random.normal(loc=0.0, scale=1.0, size=1)\n",
        "\n",
        "  def activation(self, pred):\n",
        "    return np.where(pred >= 0, 1, 0)\n",
        "\n",
        "  def prediction(self, data):\n",
        "    return self.activation(np.dot(data, self.weight.T)+self.bias)\n",
        "\n",
        "  def accuracy(self, predictions, target):\n",
        "    return np.mean(predictions==target)\n",
        "\n",
        "  def train(self, input_data, targets, epochs, lr=0.01, early_stopping=True, patience=5):\n",
        "    best_accuracy = 0\n",
        "    no_improvment_count = 0\n",
        "    history = {'loss':[], 'accuracy':[]}\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "      epoch_loss = 0\n",
        "\n",
        "      for data, target in zip(input_data, targets):\n",
        "        pred = self.prediction(data)\n",
        "        error = target - pred\n",
        "        update = lr * error\n",
        "        epoch_loss += error**2\n",
        "        self.weight += update * data\n",
        "        self.bias += update\n",
        "\n",
        "      all_pred = self.prediction(input_data)\n",
        "      epoch_accuracy = self.accuracy(all_pred, targets)\n",
        "      history['accuracy'].append(epoch_accuracy)\n",
        "      history['loss'].append(epoch_loss)\n",
        "\n",
        "      if epoch_accuracy > best_accuracy:\n",
        "        best_accuracy = epoch_accuracy\n",
        "        no_improvment_count=0\n",
        "      else:\n",
        "        no_improvment_count+=1\n",
        "\n",
        "\n",
        "      print(f\"\\r Trained Epoch {e}/{epochs}, Loss : {epoch_loss}, Accuracy : {epoch_accuracy*100: .2f}%\", end = \"\")\n",
        "\n",
        "      if early_stopping and no_improvment_count>patience:\n",
        "        print(f\"\\nEarly Stopping at epoch {e+1} \")\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "zLHaOqehU6nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "\n",
        "input_dim_m = x_train_m.shape[1]\n",
        "perc_m = Perceptron(input_dim=input_dim_m)\n",
        "\n",
        "input_dim_p = x_train_p.shape[1]\n",
        "perc_p = Perceptron(input_dim=input_dim_p)\n",
        "\n",
        "history_m = perc_m.train(x_train_m, y_train_m, epochs=50)\n",
        "history_p = perc_p.train(x_train_p, y_train_p, epochs=50)"
      ],
      "metadata": {
        "id": "-VrWU0rghK7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VISUALISING RESULTS\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_m['loss'], label='Maths Loss')\n",
        "plt.plot(history_p['loss'], label='Portugues Loss', linestyle='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('LOSS OVER EPOCH')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_m['accuracy'], label='Maths Accuracy')\n",
        "plt.plot(history_p['accuracy'], label='Portugues Accuracy', linestyle='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('ACCURACY OVER EPOCH')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Shg5rilEi4Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL EVALUATION\n",
        "\n",
        "y_pred_m = perc_m.prediction(x_test_m)\n",
        "y_pred_p = perc_p.prediction(x_test_p)\n",
        "\n",
        "acc_m = perc_m.accuracy(y_pred_m, y_test_m)\n",
        "acc_p = perc_p.accuracy(y_pred_p, y_test_p)\n",
        "\n",
        "print(f\"Test accuracy over maths dataset: {acc_m*100:.2f}%\")\n",
        "print(f\"Test accuracy over portugues dataset: {acc_p*100:.2f}%\")"
      ],
      "metadata": {
        "id": "7FOCFfwKmG0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#USER INPUT\n",
        "\n",
        "class userInput:\n",
        "  def __init__(self):\n",
        "    self.attributes = {\n",
        "            'age': None,\n",
        "            'sex': ['F', 'M'],\n",
        "            'studytime': ['1', '2', '3', '4'],\n",
        "            'failures': ['0', '1', '2', '3'],\n",
        "            'higher': ['yes', 'no'],\n",
        "            'internet': ['yes', 'no'],\n",
        "            'goout': ['1', '2', '3', '4', '5'],\n",
        "            'absences': None,\n",
        "            'G1': None,\n",
        "            'G2': None\n",
        "            }\n",
        "\n",
        "  def getInput(self):\n",
        "    user_data = {}\n",
        "    for attri, options in self.attributes.items():\n",
        "      if options is None:\n",
        "        if attri == 'age':\n",
        "          user_data[attri] = float(input(f\"Enter value for {attri} (a number between 15-22): \"))\n",
        "        elif attri == 'absences':\n",
        "          user_data[attri] = float(input(f\"Enter value for {attri} (a number between 0-98): \"))\n",
        "        else:\n",
        "          user_data[attri] = float(input(f\"Enter value for {attri} (a number between 0-20): \"))\n",
        "        continue\n",
        "\n",
        "      print(f\"Enter value for {attri} ({',' .join(options)}): \")\n",
        "      while True:\n",
        "        choice = input().strip()\n",
        "        lowered_choice = choice.lower()\n",
        "        for option in options:\n",
        "          if option.lower() == lowered_choice:\n",
        "            user_data[attri] = option\n",
        "            break\n",
        "        else:\n",
        "          print(f\"Invalid input, try entring one of these {',' .join(options)}\")\n",
        "          continue\n",
        "        break\n",
        "    return user_data"
      ],
      "metadata": {
        "id": "Bu7TqnqrK3Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_instance = userInput()\n",
        "\n",
        "user_data = user_instance.getInput()\n",
        "for attributes, value in user_data.items():\n",
        "  print(f\"{attributes} : {value}\")"
      ],
      "metadata": {
        "id": "8IRYGDbWkT4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FORMATTING USER INPUT\n",
        "\n",
        "def format_user_input(user_data, training_columns):\n",
        "  user_df = pd.DataFrame([user_data])\n",
        "  user_encoded = pd.get_dummies(user_df)\n",
        "\n",
        "  for col in training_columns:\n",
        "    if col not in user_encoded.columns:\n",
        "      user_encoded[col] = 0\n",
        "\n",
        "  user_encoded = user_encoded[training_columns]\n",
        "\n",
        "  return user_encoded\n",
        "\n",
        "training_columns_m = data_encode_m_filtered.drop('G3', axis=1).columns.tolist()\n",
        "formatted_user_m = format_user_input(user_data, training_columns_m)\n",
        "\n",
        "training_columns_p = data_encode_p_filtered.drop('G3', axis=1).columns.tolist()\n",
        "formatted_user_p = format_user_input(user_data, training_columns_p)"
      ],
      "metadata": {
        "id": "x3k5oYExSeoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCALING USER INPUT\n",
        "\n",
        "scaled_data_m = scaler_m.transform(formatted_user_m)\n",
        "scaled_data_p = scaler_p.transform(formatted_user_p)"
      ],
      "metadata": {
        "id": "I10BigqBXCUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAKING PREDICTIONS\n",
        "\n",
        "result_m = perc_m.prediction(scaled_data_m)\n",
        "result_p = perc_p.prediction(scaled_data_p)\n",
        "\n",
        "print(f\"Based on the provided inputs you are likely to {'PASS' if result_m[0]==1 else 'FAIL'} the MATHS course\")\n",
        "print(f\"Based on the provided inputs you are likelly to {'PASS' if result_p[0]==1 else 'FAIL'} the PORTUGUESE course\")\n",
        "print(f\"\\n(NOTE: This prediction is based on a model with an accuracy of {acc_m*100:.2f}% for maths and {acc_p*100:.2f}% for portuguese.)\")"
      ],
      "metadata": {
        "id": "TJyVAZMYYXoR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}